const fs = require('fs');
const Buffer = require('buffer').Buffer;

const DQUOTE = '"';
const CR = '\r';
const LF = '\n';
const CRLF = '\r\n';

const token_enum = {
    'DELIM': 0,
    'DQUOTE': 1,
    'CR': 2,
    'LF': 3,
    'CRLF': 4,
    'TEXTDATA': 5
}

const state_enum = {
    'INITIAL': 0,
    'REST': 1,
    'RECORD': 2,
    'RECORDREST': 3,
    'FIELD': 4,
    'ESCAPED': 5,
    'NONESCAPED': 6,
    'TWODQUOTE': 7
}

function parse_dsv_stream(DELIM = ',') {

    let csv_state = [];
    let buffer = [];
    let state = state_enum.INITIAL;
    let row = -1;
    let column = -1;

    return incrparse;

    // bytes should be an array
    // an array of characters (strings with length 1)
    function incrparse(chars) {
        buffer = buffer.concat(chars);
        attemptParse();
        return csv_state;
    }

    function readNextTokens() {
        const tokens = [];
        while (buffer.length > 0) {
            const char = buffer.shift();
            switch (char) {
                case DELIM[0]: // initial delimiter character
                    // already guaranteed first character matches
                    let delimbuf = buffer.splice(0, DELIM.length - 1);
                    if (delimbuf.some((ele, i) => ele !== DELIM[i + 1])) { // at least 1 char doesn't match up
                        tokens.push({ type: token_enum.TEXTDATA, data: char }); // constraint: delimiter must start with TEXTDATA type
                        // questionable when delimiter is repeating pattern
                        buffer = delimbuf.concat(buffer); // put things back on top
                    } else if (delimbuf.length === DELIM.length - 1) { // matches all characters
                        tokens.push({ type: token_enum.DELIM, data: DELIM });
                    } else { // match so far but not enough characters to determine
                        buffer = delimbuf.concat(buffer);
                        buffer.unshift(char);
                        return tokens;
                    }
                    break;
                case CR:
                    if (buffer.length < 1)  {
                        buffer.unshift(char); // put byte back into buffer;
                        return tokens; // need at least 1 more byte to determine token
                    }
                    const char2 = buffer.shift();
                    if (char2 === LF)
                        tokens.push({ type: token_enum.CRLF, data: CRLF });
                    else {
                        buffer.unshift(char2);
                        tokens.push({ type: token_enum.CR, data: CR });
                    }
                    break;
                case LF:
                    tokens.push({ type: token_enum.LF, data: LF });
                    break;
                case DQUOTE:
                    tokens.push({ type: token_enum.DQUOTE, data: DQUOTE });
                    break;
                default:
                    tokens.push({ type: token_enum.TEXTDATA, data: char });
            }
        }
        return tokens;
    }

/* The ABNF grammar [2] appears as follows:

   file = [header CRLF] record *(CRLF record) [CRLF]
   header = name *(COMMA name)
   record = field *(COMMA field)
   name = field
   field = (escaped / non-escaped)
   escaped = DQUOTE *(TEXTDATA / COMMA / CR / LF / 2DQUOTE) DQUOTE
   non-escaped = *TEXTDATA
   COMMA = %x2C
   CR = %x0D ;as per section 6.1 of RFC 2234 [2]
   DQUOTE =  %x22 ;as per section 6.1 of RFC 2234 [2]
   LF = %x0A ;as per section 6.1 of RFC 2234 [2]
   CRLF = CR LF ;as per section 6.1 of RFC 2234 [2]
   TEXTDATA =  %x20-21 / %x23-2B / %x2D-7E

*/

    function attemptParse() {
        let tokens = readNextTokens();
        while (tokens.length > 0) {
            const token = tokens.shift();
            switch (state) {
                case state_enum.INITIAL: // initial state
                    csv_state.push([]);
                    row++;
                    column = -1;
                case state_enum.RECORD: // start of a row
                    column++;
                    switch (token.type) {
                        case token_enum.DQUOTE:
                            csv_state[row][column] = '';
                            state = state_enum.ESCAPED;
                            break;
                        case token_enum.TEXTDATA:
                            csv_state[row][column] = token.data;
                            state = state_enum.NONESCAPED;
                            break;
                        case token_enum.DELIM:
                            csv_state[row][column] = '';
                            state = state_enum.RECORD;
                            break;
                        case token_enum.CRLF:
                        case token_enum.CR:
                        case token_enum.LF:
                            csv_state[row][column] = '';
                            state = state_enum.INITIAL;
                            break;
                        default:
                            throw new Error(state + ". unexpected token " + token.type);
                    }
                    break;
                case state_enum.ESCAPED:
                    switch (token.type) {
                        case token_enum.TEXTDATA:
                        case token_enum.DELIM:
                        case token_enum.CR:
                        case token_enum.LF:
                        case token_enum.CRLF:
                            if (!csv_state[row][column]) csv_state[row][column] = token.data;
                            else csv_state[row][column] += token.data;
                            break;
                        case token_enum.DQUOTE:
                            state = state_enum.TWODQUOTE;
                            break;
                        default:
                            throw new Error(state + ". unexpected token " + token.type);
                    }
                    break;
                case state_enum.NONESCAPED:
                    switch (token.type) {
                        case token_enum.TEXTDATA:
                            csv_state[row][column] += token.data;
                            break;
                        case token_enum.DELIM:
                            state = state_enum.RECORD;
                            break;
                        case token_enum.CRLF:
                        case token_enum.CR:
                        case token_enum.LF:
                            state = state_enum.INITIAL;
                            break;
                        default:
                            throw new Error(state + ". unexpected token " + token.type);
                    }
                    break;
                case state_enum.TWODQUOTE:
                    switch (token.type) {
                        case token_enum.DQUOTE:
                            csv_state[row][column] += DQUOTE;
                            state = state_enum.ESCAPED;
                            break;
                        case token_enum.DELIM:
                            state = state_enum.RECORD;
                            break;
                        case token_enum.CRLF:
                        case token_enum.CR:
                        case token_enum.LF:
                            state = state_enum.INITIAL;
                            break;
                        default:
                            throw new Error(state + ". unexpected token " + token.type);
                    }
                    break;
            }
        }
    }
}

module.exports = parse_dsv_stream;
